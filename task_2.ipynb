{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taks 1 – BYOD (Bring Your Own Data) [10 points]\n",
    "- Craft a compelling introduction for your project. Describe the dataset that you are going\n",
    "to use, introduce the background, explain its significance, and share your motivation for\n",
    "choosing it.\n",
    "- Highlight the potential impact of a successful solution and anticipate any challenges\n",
    "ahead. This introduction should encapsulate the essence of your project, drawing\n",
    "readers in with clarity and conviction, while setting the stage for the details to follow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/lukebarousse/data_jobs   ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 – EDA [10 points]\n",
    "Perform exploratory analysis on the data. Research online for ideas, and then show analysis on\n",
    "at least five different aspects of the dataset. Analyze your findings.\n",
    "Note: This part is open-ended, any valid analysis is fine as long as it useful for you to\n",
    "understand the data better! Use visualizations when necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/lukebarousse/data_jobs/data_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22003.000000</td>\n",
       "      <td>10662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123286.274072</td>\n",
       "      <td>47.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48312.449482</td>\n",
       "      <td>21.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90000.000000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115000.000000</td>\n",
       "      <td>45.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>61.159996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>960000.000000</td>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary_year_avg  salary_hour_avg\n",
       "count     22003.000000     10662.000000\n",
       "mean     123286.274072        47.016598\n",
       "std       48312.449482        21.890738\n",
       "min       15000.000000         8.000000\n",
       "25%       90000.000000        27.500000\n",
       "50%      115000.000000        45.980000\n",
       "75%      150000.000000        61.159996\n",
       "max      960000.000000       391.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 – Problem Definition [10 points]\n",
    "Based on Task 2, revisit Task 1 to write a compelling introduction for your project that also\n",
    "highlights the problem that you are going to solve and some observations to support the choice,\n",
    "motivation and significance based on your EDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4 – Preprocessing [10 points]\n",
    "Perform data processing on the data. Dive deep into data preparation, ensuring that the dataset\n",
    "is primed and ready for model training. Document all preprocessing steps and include them in\n",
    "the report, specify what happened to the data after the step, why you performed it and if you are\n",
    "going to use it moving forward.\n",
    "For example:\n",
    "1. Data Cleaning: Address any inconsistencies within the data. This includes dealing with\n",
    "missing values, anomalies, and duplicated entries.\n",
    "2. Data Transformation & Normalization: Depending on the nature and distribution of\n",
    "your data, apply necessary transformations. Ensure features are on a similar scale,\n",
    "making them more amenable to analysis and model training.\n",
    "3. Specific Data Type Processing:\n",
    "a. Text Data: Implement tokenization to break down text into smaller chunks,\n",
    "remove stop words to filter out common but uninformative words, and utilize\n",
    "feature extraction techniques, like TF-IDF or word embeddings, to represent text\n",
    "in a form suitable for machine learning.\n",
    "b. Image Data: Normalize image pixel values, ensuring they fall within a consistent\n",
    "range (typically 0 to 1). Consider image augmentation techniques to artificially\n",
    "enhance your dataset, creating varied representations of the same image to\n",
    "improve model robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5 – Model Selection, Training, and Optimization [20 points]\n",
    "1. Identify and train at least five distinct machine learning models apt for your regression\n",
    "task.\n",
    "2. try to boost the performance of the models using suitable techniques. For example,\n",
    "feature engineering, cross-validation, grid search, tuning model hyperparameters, etc.\n",
    "Try at least three techniques and compare the performance with the vanilla ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6 – Model Evaluation [20 points]\n",
    "1. Use at least four metrics to evaluate the performance of your selected models.\n",
    "2. Analyze the experimental results and report your conclusion. The analysis should\n",
    "compare results (using the metrics you chose above) the different pre-processing steps\n",
    "(Task 4), the different models and optimization steps (Task 5) in a table/graph.\n",
    "3. Report your observations discuss their implications (e.g., Model X with Optimization Y\n",
    "after preprocessing step Z was the most/least effective because ABC...).\n",
    "4. In your report, you should refer explicitly to the nature of analysis each evaluation\n",
    "measure provides and the benefits from using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7 – Explainability [20 points]\n",
    "For this task, you will focus on making your regression model interpretable and understandable.\n",
    "In the world of machine learning, explainability is key for building trust in the model and\n",
    "understanding its decision-making process.\n",
    "1. Use at least two techniques for explanations.\n",
    "2. Explain Model Predictions: Use appropriate tools and techniques (e.g., SHAP, LIME, etc)\n",
    "to explain how your model is making predictions. Analyze the importance of each feature\n",
    "in influencing the model’s output. Highlight the key drivers behind the predictions.\n",
    "3. Explore Feature Importance: Evaluate and rank the features based on their contribution to the\n",
    "prediction task. Provide a discussion on how different features impact the model’s performance\n",
    "and predictions. Focus on understanding the relationship between the features and the target\n",
    "variable.\n",
    "4. Present Results in an Intuitive Way: Visualize the model's explainability using graphs and\n",
    "charts that clearly communicate the findings.\n",
    "Some good examples for you: features_importance, LIME - Local Interpretable Model-Agnostic\n",
    "Explanations, An introduction to explainable AI with Shapley values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
