{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taks 1 – BYOD (Bring Your Own df) [10 points]\n",
    "- Craft a compelling introduction for your project. Describe the dfset that you are going\n",
    "to use, introduce the background, explain its significance, and share your motivation for\n",
    "choosing it.\n",
    "- Highlight the potential impact of a successful solution and anticipate any challenges\n",
    "ahead. This introduction should encapsulate the essence of your project, drawing\n",
    "readers in with clarity and conviction, while setting the stage for the details to follow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/dfsets/gauss314/options-IV-SP500   ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "import numpy as np\n",
    "from models import model_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 – EDA [10 points]\n",
    "Perform exploratory analysis on the df. Research online for ideas, and then show analysis on\n",
    "at least five different aspects of the dfset. Analyze your findings.\n",
    "Note: This part is open-ended, any valid analysis is fine as long as it useful for you to\n",
    "understand the df better! Use visualizations when necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/gauss314/options-IV-SP500/data_IV_USA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning for eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3161661 entries, 0 to 3161660\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   symbol                  object \n",
      " 1   date                    object \n",
      " 2   strikes_spread          float64\n",
      " 3   calls_contracts_traded  int64  \n",
      " 4   puts_contracts_traded   int64  \n",
      " 5   calls_open_interest     int64  \n",
      " 6   puts_open_interest      int64  \n",
      " 7   expirations_number      int64  \n",
      " 8   DITM_IV                 float64\n",
      " 9   ITM_IV                  float64\n",
      " 10  sITM_IV                 float64\n",
      " 11  ATM_IV                  float64\n",
      " 12  sOTM_IV                 float64\n",
      " 13  OTM_IV                  float64\n",
      " 14  DOTM_IV                 float64\n",
      " 15  contracts_number        int64  \n",
      " 16  hv_20                   float64\n",
      " 17  hv_40                   float64\n",
      " 18  hv_60                   float64\n",
      " 19  hv_75                   float64\n",
      " 20  hv_90                   float64\n",
      " 21  hv_120                  float64\n",
      " 22  hv_180                  float64\n",
      " 23  hv_200                  float64\n",
      " 24  VIX                     float64\n",
      "dtypes: float64(17), int64(6), object(2)\n",
      "memory usage: 603.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3161661 entries, 0 to 3161660\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   symbol                  object \n",
      " 1   date                    object \n",
      " 2   strikes_spread          float64\n",
      " 3   calls_contracts_traded  int64  \n",
      " 4   puts_contracts_traded   int64  \n",
      " 5   calls_open_interest     int64  \n",
      " 6   puts_open_interest      int64  \n",
      " 7   expirations_number      int64  \n",
      " 8   DITM_IV                 float64\n",
      " 9   ITM_IV                  float64\n",
      " 10  sITM_IV                 float64\n",
      " 11  ATM_IV                  float64\n",
      " 12  sOTM_IV                 float64\n",
      " 13  OTM_IV                  float64\n",
      " 14  DOTM_IV                 float64\n",
      " 15  contracts_number        int64  \n",
      " 16  hv_20                   float64\n",
      " 17  hv_40                   float64\n",
      " 18  hv_60                   float64\n",
      " 19  hv_75                   float64\n",
      " 20  hv_90                   float64\n",
      " 21  hv_120                  float64\n",
      " 22  hv_180                  float64\n",
      " 23  hv_200                  float64\n",
      " 24  VIX                     float64\n",
      "dtypes: float64(17), int64(6), object(2)\n",
      "memory usage: 603.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strikes_spread</th>\n",
       "      <th>calls_contracts_traded</th>\n",
       "      <th>puts_contracts_traded</th>\n",
       "      <th>calls_open_interest</th>\n",
       "      <th>puts_open_interest</th>\n",
       "      <th>expirations_number</th>\n",
       "      <th>DITM_IV</th>\n",
       "      <th>ITM_IV</th>\n",
       "      <th>sITM_IV</th>\n",
       "      <th>ATM_IV</th>\n",
       "      <th>...</th>\n",
       "      <th>contracts_number</th>\n",
       "      <th>hv_20</th>\n",
       "      <th>hv_40</th>\n",
       "      <th>hv_60</th>\n",
       "      <th>hv_75</th>\n",
       "      <th>hv_90</th>\n",
       "      <th>hv_120</th>\n",
       "      <th>hv_180</th>\n",
       "      <th>hv_200</th>\n",
       "      <th>VIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "      <td>3161661.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.89</td>\n",
       "      <td>1383.88</td>\n",
       "      <td>1380.70</td>\n",
       "      <td>27970.24</td>\n",
       "      <td>25912.96</td>\n",
       "      <td>3.71</td>\n",
       "      <td>52.05</td>\n",
       "      <td>48.35</td>\n",
       "      <td>45.77</td>\n",
       "      <td>43.93</td>\n",
       "      <td>...</td>\n",
       "      <td>154.68</td>\n",
       "      <td>47.13</td>\n",
       "      <td>48.30</td>\n",
       "      <td>48.64</td>\n",
       "      <td>48.83</td>\n",
       "      <td>48.97</td>\n",
       "      <td>49.15</td>\n",
       "      <td>49.30</td>\n",
       "      <td>49.51</td>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.59</td>\n",
       "      <td>8573.14</td>\n",
       "      <td>10785.30</td>\n",
       "      <td>156677.10</td>\n",
       "      <td>184192.18</td>\n",
       "      <td>1.75</td>\n",
       "      <td>23.51</td>\n",
       "      <td>24.62</td>\n",
       "      <td>24.40</td>\n",
       "      <td>23.65</td>\n",
       "      <td>...</td>\n",
       "      <td>251.09</td>\n",
       "      <td>2749.27</td>\n",
       "      <td>1976.54</td>\n",
       "      <td>1620.96</td>\n",
       "      <td>1452.42</td>\n",
       "      <td>1327.48</td>\n",
       "      <td>1151.44</td>\n",
       "      <td>941.71</td>\n",
       "      <td>731.95</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>11.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.20</td>\n",
       "      <td>35.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>175.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>35.57</td>\n",
       "      <td>30.82</td>\n",
       "      <td>28.44</td>\n",
       "      <td>27.43</td>\n",
       "      <td>...</td>\n",
       "      <td>43.00</td>\n",
       "      <td>21.87</td>\n",
       "      <td>23.67</td>\n",
       "      <td>24.67</td>\n",
       "      <td>25.20</td>\n",
       "      <td>25.63</td>\n",
       "      <td>26.22</td>\n",
       "      <td>27.25</td>\n",
       "      <td>28.92</td>\n",
       "      <td>17.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.03</td>\n",
       "      <td>154.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>1291.00</td>\n",
       "      <td>695.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>45.61</td>\n",
       "      <td>41.64</td>\n",
       "      <td>39.65</td>\n",
       "      <td>38.22</td>\n",
       "      <td>...</td>\n",
       "      <td>86.00</td>\n",
       "      <td>32.90</td>\n",
       "      <td>34.89</td>\n",
       "      <td>36.16</td>\n",
       "      <td>36.95</td>\n",
       "      <td>37.62</td>\n",
       "      <td>38.65</td>\n",
       "      <td>39.96</td>\n",
       "      <td>41.42</td>\n",
       "      <td>21.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.04</td>\n",
       "      <td>654.00</td>\n",
       "      <td>592.00</td>\n",
       "      <td>9514.00</td>\n",
       "      <td>6150.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>61.72</td>\n",
       "      <td>58.79</td>\n",
       "      <td>56.66</td>\n",
       "      <td>54.52</td>\n",
       "      <td>...</td>\n",
       "      <td>182.00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.28</td>\n",
       "      <td>55.06</td>\n",
       "      <td>55.95</td>\n",
       "      <td>56.65</td>\n",
       "      <td>57.56</td>\n",
       "      <td>58.62</td>\n",
       "      <td>59.23</td>\n",
       "      <td>26.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>375.00</td>\n",
       "      <td>1567830.00</td>\n",
       "      <td>1381840.00</td>\n",
       "      <td>7121560.00</td>\n",
       "      <td>9221790.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10808.00</td>\n",
       "      <td>3468890.00</td>\n",
       "      <td>2484930.00</td>\n",
       "      <td>2037590.00</td>\n",
       "      <td>1825560.00</td>\n",
       "      <td>1668380.00</td>\n",
       "      <td>1446880.00</td>\n",
       "      <td>1183030.00</td>\n",
       "      <td>917394.00</td>\n",
       "      <td>82.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strikes_spread  calls_contracts_traded  puts_contracts_traded  \\\n",
       "count      3161661.00              3161661.00             3161661.00   \n",
       "mean            14.89                 1383.88                1380.70   \n",
       "std             15.59                 8573.14               10785.30   \n",
       "min              0.33                    0.00                   0.00   \n",
       "25%              4.20                   35.00                  21.00   \n",
       "50%              9.03                  154.00                 120.00   \n",
       "75%             21.04                  654.00                 592.00   \n",
       "max            375.00              1567830.00             1381840.00   \n",
       "\n",
       "       calls_open_interest  puts_open_interest  expirations_number    DITM_IV  \\\n",
       "count           3161661.00          3161661.00          3161661.00 3161661.00   \n",
       "mean              27970.24            25912.96                3.71      52.05   \n",
       "std              156677.10           184192.18                1.75      23.51   \n",
       "min                   0.00                0.00                1.00       1.57   \n",
       "25%                 175.00               83.00                3.00      35.57   \n",
       "50%                1291.00              695.00                3.00      45.61   \n",
       "75%                9514.00             6150.00                5.00      61.72   \n",
       "max             7121560.00          9221790.00               25.00     149.00   \n",
       "\n",
       "          ITM_IV    sITM_IV     ATM_IV  ...  contracts_number      hv_20  \\\n",
       "count 3161661.00 3161661.00 3161661.00  ...        3161661.00 3161661.00   \n",
       "mean       48.35      45.77      43.93  ...            154.68      47.13   \n",
       "std        24.62      24.40      23.65  ...            251.09    2749.27   \n",
       "min         1.57       1.04       1.00  ...              3.00       0.00   \n",
       "25%        30.82      28.44      27.43  ...             43.00      21.87   \n",
       "50%        41.64      39.65      38.22  ...             86.00      32.90   \n",
       "75%        58.79      56.66      54.52  ...            182.00      50.37   \n",
       "max       149.00     149.00     149.00  ...          10808.00 3468890.00   \n",
       "\n",
       "           hv_40      hv_60      hv_75      hv_90     hv_120     hv_180  \\\n",
       "count 3161661.00 3161661.00 3161661.00 3161661.00 3161661.00 3161661.00   \n",
       "mean       48.30      48.64      48.83      48.97      49.15      49.30   \n",
       "std      1976.54    1620.96    1452.42    1327.48    1151.44     941.71   \n",
       "min         0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "25%        23.67      24.67      25.20      25.63      26.22      27.25   \n",
       "50%        34.89      36.16      36.95      37.62      38.65      39.96   \n",
       "75%        53.28      55.06      55.95      56.65      57.56      58.62   \n",
       "max   2484930.00 2037590.00 1825560.00 1668380.00 1446880.00 1183030.00   \n",
       "\n",
       "          hv_200        VIX  \n",
       "count 3161661.00 3161661.00  \n",
       "mean       49.51      23.25  \n",
       "std       731.95       8.60  \n",
       "min         0.13      11.54  \n",
       "25%        28.92      17.70  \n",
       "50%        41.42      21.84  \n",
       "75%        59.23      26.87  \n",
       "max    917394.00      82.69  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 – Problem Definition [10 points]\n",
    "Based on Task 2, revisit Task 1 to write a compelling introduction for your project that also\n",
    "highlights the problem that you are going to solve and some observations to support the choice,\n",
    "motivation and significance based on your EDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4 – Preprocessing [10 points]\n",
    "Perform df processing on the df. Dive deep into df preparation, ensuring that the dfset\n",
    "is primed and ready for model training. Document all preprocessing steps and include them in\n",
    "the report, specify what happened to the df after the step, why you performed it and if you are\n",
    "going to use it moving forward.\n",
    "For example:\n",
    "1. df Cleaning: Address any inconsistencies within the df. This includes dealing with\n",
    "missing values, anomalies, and duplicated entries.\n",
    "2. df Transformation & Normalization: Depending on the nature and distribution of\n",
    "your df, apply necessary transformations. Ensure features are on a similar scale,\n",
    "making them more amenable to analysis and model training.\n",
    "3. Specific df Type Processing:\n",
    "a. Text df: Implement tokenization to break down text into smaller chunks,\n",
    "remove stop words to filter out common but uninformative words, and utilize\n",
    "feature extraction techniques, like TF-IDF or word embeddings, to represent text\n",
    "in a form suitable for machine learning.\n",
    "b. Image df: Normalize image pixel values, ensuring they fall within a consistent\n",
    "range (typically 0 to 1). Consider image augmentation techniques to artificially\n",
    "enhance your dfset, creating varied representations of the same image to\n",
    "improve model robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5 – Model Selection, Training, and Optimization [20 points]\n",
    "1. Identify and train at least five distinct machine learning models apt for your regression\n",
    "task.\n",
    "2. try to boost the performance of the models using suitable techniques. For example,\n",
    "feature engineering, cross-validation, grid search, tuning model hyperparameters, etc.\n",
    "Try at least three techniques and compare the performance with the vanilla ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat = ['strikes_spread', 'calls_contracts_traded', 'puts_contracts_traded', \n",
    "            'calls_open_interest', 'puts_open_interest', 'expirations_number', \n",
    "            'contracts_number', 'hv_20', 'hv_40', 'hv_60', 'hv_120', 'hv_180', 'VIX']\n",
    "\n",
    "X = df[feat]\n",
    "y = df['DITM_IV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: None, R2: None, MAE: None, Explained Variance Score: None, MSE: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RMSE: 18.819799000620527, R2: 0.36036620914771755, MAE: 13.29255651359572, Explained Variance Score: 0.3603669255998555, MSE: 354.1848344237574'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_picker('OLS Linear Regression', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_picker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRandom Forest Regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\KDDProject3-1\\models.py:32\u001b[0m, in \u001b[0;36mmodel_picker\u001b[1;34m(type, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mn_estimators, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Random Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mn_estimators):\n\u001b[0;32m     33\u001b[0m         model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     34\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_picker('Random Forest Regression', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_picker('Gradient Boosting Regression', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_picker(\"Support Vector Regression\", X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_picker('LSTM', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_picker('SGD Linear Regression', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_picker('Deep Neural Network', X_train = X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347.4702936312111,\n",
       " 0.3727574349758219,\n",
       " 18.64055507840931,\n",
       " 13.216486380311,\n",
       " 0.3727575444954596)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do some feature engineering\n",
    "\n",
    "df['interaction_open_interest'] = df['calls_open_interest'] * df['puts_open_interest']\n",
    "df['calls_to_puts_traded_ratio'] = df['calls_contracts_traded'] / (df['puts_contracts_traded'] + 1)  # Adding 1 to avoid division by zero, went over it in class\n",
    "df['log_calls_traded'] = np.log1p(df['calls_contracts_traded'])  # log1p to handle zero values\n",
    "df['log_puts_traded'] = np.log1p(df['puts_contracts_traded']) # see comment above\n",
    "new_features = ['strikes_spread', 'calls_contracts_traded', 'puts_contracts_traded', \n",
    "                'calls_open_interest', 'puts_open_interest', 'expirations_number', \n",
    "                'contracts_number', 'hv_20', 'hv_40', 'hv_60', 'hv_120', 'hv_180', 'VIX',\n",
    "                'interaction_open_interest', 'calls_to_puts_traded_ratio', 'log_calls_traded', 'log_puts_traded']\n",
    "\n",
    "X_new = df[new_features]\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "X_train_new_scaled = scaler.fit_transform(X_train_new)\n",
    "X_test_new_scaled = scaler.transform(X_test_new)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do some grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do some k fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6 – Model Evaluation [20 points]\n",
    "1. Use at least four metrics to evaluate the performance of your selected models.\n",
    "2. Analyze the experimental results and report your conclusion. The analysis should\n",
    "compare results (using the metrics you chose above) the different pre-processing steps\n",
    "(Task 4), the different models and optimization steps (Task 5) in a table/graph.\n",
    "3. Report your observations discuss their implications (e.g., Model X with Optimization Y\n",
    "after preprocessing step Z was the most/least effective because ABC...).\n",
    "4. In your report, you should refer explicitly to the nature of analysis each evaluation\n",
    "measure provides and the benefits from using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7 – Explainability [20 points]\n",
    "For this task, you will focus on making your regression model interpretable and understandable.\n",
    "In the world of machine learning, explainability is key for building trust in the model and\n",
    "understanding its decision-making process.\n",
    "1. Use at least two techniques for explanations.\n",
    "2. Explain Model Predictions: Use appropriate tools and techniques (e.g., SHAP, LIME, etc)\n",
    "to explain how your model is making predictions. Analyze the importance of each feature\n",
    "in influencing the model’s output. Highlight the key drivers behind the predictions.\n",
    "3. Explore Feature Importance: Evaluate and rank the features based on their contribution to the\n",
    "prediction task. Provide a discussion on how different features impact the model’s performance\n",
    "and predictions. Focus on understanding the relationship between the features and the target\n",
    "variable.\n",
    "4. Present Results in an Intuitive Way: Visualize the model's explainability using graphs and\n",
    "charts that clearly communicate the findings.\n",
    "Some good examples for you: features_importance, LIME - Local Interpretable Model-Agnostic\n",
    "Explanations, An introduction to explainable AI with Shapley values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
